# VAE - 변이형 오토인코더

- 변이형 오토인코더는 생성 모델링에서 가장 기본적이고 널리 알려진 딥러닝 구조 중 하나

## AE - 오토인코더

AE는 인코더와 디코더로 이루어진 신경망

- 인코더 네트워크 : 고차원 입력 데이터를 저차원 표현 벡터로 압축
- 디코더 네트워크 : 주어진 표현 벡터를 원본 차원으로 다시 압축 해제 (잠재 공간에 있는 포인트를 올바른 이미지로 변환하는 방법 학습)

원본 입력은 인코더와 디코더를 지나 재구성 이미지가 되며 입력과 재구성 사이의 손실을 최소화하는 인코더와 디코더의 가중치를 찾기 위해 네트워크가 훈련된다.

인코더는 보통 2개 이상의 차원을 가진다 -> 이미지에 있는 미묘한 차이를 잘 감지하도록 더 높은 자유도를 주기 위해

인코더를 학습하여 잠재 공간 안에 랜덤한 잡음을 나타내기 어려움 -> AE는 이미지에서 잡음을 제거하기 위해 사용 가능

### 문제점

잠재 공간에 포인트가 적은 영역이 큰 경우 매우 적은 이미지가 인코딩되어 있기에 AE가 또렷한 숫자로 디코딩 할 수 없다 -> AE가 잠재 공간을 연속적으로 만들지 않기 때문

2차원의 경우 AE 차원이 적기 때문에 잠재 공간에 조밀하게 채울 수 있어 그룹 간의 간격이 좁지만 얼굴처럼 복잡한 이미지의 경우 이 문제가 또렷해짐

## VAE

AE를 VAE로 바꾸어 생성 모델을 만들기 위해 바꾸어야할 부분은 **인코더와 손실 함수** 딱 두 군데이다

### 인코더

AE에서는 이미지가 잠재 공간의 한 포인트에 직접 매핑이 되며 VAE는 각 이미지가 잠재 공간에 있는 포인트 주변의 다변수 졍규 분포에 매핑된다.

인코더는 입력 이미지를 받아 잠재 공간의 다변수 정규 분포를 정의하는 2개의 벡터 **mu**와 **log_var**로 인코딩 한다

- mu : 이 분포의 평균 벡터 
- log_var : 차원별 분산의 로그값

`z = mu + sigma * epsilon `  (특정 포인트 z로 인코딩하기)

- mu : 엔코더씨 의견

- epsilon : mu에서 얼마나 떨어져 표시해야 하는지를 나타냄 (입실론 양의 랜덤한 선택) 

- sigma : 표시 위치에 대한 엔 코더씨의 확신

`sigma = exp(log_var / 2)`

이전에는 잠재 공간을 연속적으로 만들 필요가 없었지만 이제는 mu 주변의 지역에서 랜덤한 포인트로 샘플링하기 때문에 디보더는 같은 영역에 위치한 포인트를 매우 비슷한 이미지로 디코딩 해야함

### 손실 함수

- 이전 손실 함수는 원본 이미지와 인코더와 디코더를 통과한 재구성 사이의 RMSE 손실로만 구성 -> 재구성 손실로 VAE에도 적용

- VAE는 추가적으로 쿨백-라이블러 발산(KL 발산) 사용

KL 발산 : 한 확률 분포가 다른 분포와 얼마나 다른지 측정하는 도구

- 표준 정규 분포(mu(평균) = 0, log_var(분산) = 0)에서 크게 벗어난 mu와 log_var 변수로 인코딩하는 네트워크에 벌칙을 가한다

## VAE 분석

최종 목적은 잠재 공간으로부터 샘플링하여 새로운 얼굴 이미지를 생성하는 것

-> 잠재 공간의 포인트 분포가 다변수 표준 정규 분포와 비슷한지 확인해야 한다 

-> 어떤 차원이 표준 정규 분포와 크게 다르다면 KL 발산항이 충분히 영향을 미치지 못한 것이므로 재구성 손실 가중치를 감소시켜야 함