# 쓰기

#### 텍스트 데이터와 이미지 데이터 사이의 차이점

- 텍스트 데이터는 개별적인 데이터 조각으로 구성 반면 이미지 픽셀은 연속적인 색상 스펙트럼 위의 한 점 -> 텍스트 데이터는 일반적인 방식으로 역전파 적용 불가
- 텍스트 데이터는 시간 차원이 있지만 공간 차원은 없음 반면 이미지 데이터는 두 개의 공간 차원이 있고 시간 차원이 없음
- 텍스트 데이터는 개별 단위의 작은 변화에도 매우 민감
- 텍스트 데이터는 규칙 기반을 가진 문법 구조를 가짐

순차 데이터를 생성하는 데 가장 유용하고 성공적인 모델 중에 하나인 **순환 신경망과 LSTM층** 알아보기

## LSTM 네트워크 소개

- LSTM 네트워크는 순환 신경망(RNN) 의 한 종류
- RNN은 특정 타임스텝의 출력이 다음 타임스템 입력의 일부분으로 사용

## 첫 번째 LSTM 네트워크

데이터를 적절한 형태로 가공하기

### 토큰화

**토큰화** : 텍스트를 단어나 문자와 같은 개별 단위로 나누는 작업

#### 단어 토큰의 경우

- 모든 텍스트를 소문자로 변환
- 어휘사전(훈련 세트에 있는 고유한 단어의 모음)이 매우 클 수 있음 -> 희소한 단어는 별도의 토큰 보다 알려지지 않은 단어에 해당하는 토큰으로 바꾸기
- 단어에서 어간 추출하기(browse, browsing, browses는 모두 brows)
- 구두점(마침표와 쉼표)을 토큰화하거나 모두 제거해야 함
- 단어 토큰화를 사용하면 훈련 어휘 사전에 없는 단어는 모델이 예측 불가

#### 문자 토큰의 경우

- 모델이 문자의 시퀀스를 생성해 훈련 어휘 사전에 없는 새로운 단어 만들 수 있음 
- 대문자는 소문자로 바꾸거나 별도의 토큰으로 남길 수 있음
- 문자 토큰화를 사용하면 어휘 사전이 비교적 매우 작음 -> 마지막 출력층에 학습할 가중치 수가 적기에 훈련 속도에 유리

